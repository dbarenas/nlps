{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orange County, California\n",
      "settlement\n",
      "place\n",
      "populated place\n",
      "owl#Thing\n",
      "place\n",
      "1889 establishments in the United States\n",
      "Orange County, California\n",
      "California counties\n",
      "Government units that have filed for Chapter 9 bankruptcy\n",
      "William III of England\n",
      "royalty\n",
      "http://xmlns.com/foaf/0.1/ person\n",
      "person\n",
      "agent\n",
      "british royalty\n",
      "owl#Thing\n",
      "person\n",
      "Dutch Anglicans\n",
      "Princes of Orange\n",
      "Anti-Catholicism in England\n",
      "Anti-Catholicism in Ireland\n",
      "Lord High Admirals\n",
      "Burials at Westminster Abbey\n",
      "Modern child rulers\n",
      "Deaths by horse-riding accident\n",
      "Dutch people of Scottish descent\n",
      "People from The Hague\n",
      "English pretenders to the French throne\n",
      "Williamite military personnel of the Williamite War in Ireland\n",
      "1650 births\n",
      "Counts of Nassau\n",
      "Scottish monarchs\n",
      "Lords of Breda\n",
      "Anti-Catholicism in Scotland\n",
      "Protestant monarchs\n",
      "House of Orange-Nassau\n",
      "Knights of the Garter\n",
      "Glorious Revolution\n",
      "1702 deaths\n",
      "Accidental deaths in England\n",
      "Dutch stadtholders\n",
      "Anti-Catholicism in Wales\n",
      "British military personnel of the Nine Years' War\n",
      "English monarchs\n",
      "William III of England\n",
      "Stellar classification\n",
      "Stars by luminosity class\n",
      "Star types\n",
      "Stellar astronomy\n",
      "Hertzsprung-Russell classifications\n",
      "Classification systems\n",
      "Stars\n",
      "Stars by spectral type\n",
      "Orange (fruit)\n",
      "eukaryote\n",
      "owl#Thing\n",
      "species\n",
      "plant\n",
      "Oranges\n",
      "Tropical agriculture\n",
      "Symbols of Florida\n",
      "Citrus hybrids\n",
      "Symbols of California\n",
      "United States state plants\n",
      "San Bernardino, California\n",
      "settlement\n",
      "place\n",
      "populated place\n",
      "city\n",
      "owl#Thing\n",
      "place\n",
      "city\n",
      "Neighborhoods in San Bernardino, California\n",
      "San Bernardino, California\n",
      "County seats in California\n",
      "Populated places on the Santa Ana River\n",
      "Inland Empire (California)\n",
      "Communities on U.S. Route 66\n",
      "Populated places in California with Hispanic majority populations\n",
      "Cities in San Bernardino County, California\n",
      "Incorporated cities and towns in California\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "# please enter a word to check\n",
    "centerWord=\"Orange\"\n",
    "def keywords(centerWord):\n",
    "    url = \"http://lookup.dbpedia.org/api/search.asmx/KeywordSearch?QueryClass=&QueryString=\"+centerWord\n",
    "    req = requests.get(url)\n",
    "\n",
    "    statusCode = req.status_code\n",
    "    htmlText = req.text\n",
    "\n",
    "    # Comprobamos que la peticiÃ³n nos devuelve un Status Code = 200\n",
    "    statusCode = req.status_code\n",
    "\n",
    "    results = []\n",
    "    if statusCode == 200:\n",
    "        html = BeautifulSoup(req.text, \"lxml\")\n",
    "        res = html.find_all('label', {'': ''})\n",
    "\n",
    "    for i in res:\n",
    "        #print(i)\n",
    "        print(i.getText())\n",
    "    \n",
    "keywords(centerWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orgs=['Pfizer', 'Novartis', 'Roche', 'Merck & co', 'Sanofi', 'Gilead Sciences', 'Johnson & Johnson', 'GlaxoSmithKline', 'AstraZeneca', 'Abbvie', 'Amgen', 'Allergan', 'Teva Pharmaceutical Industries', 'Novo Nordisk', 'Eli Lilly', 'Bayer', 'Bristol-Myers Squibb', 'Takeda', 'Boehringer Ingelheim', 'Astellas Pharma', 'Mylan', 'Biogen', 'Celgene', 'Merck KGaA', 'Daiichi Sankyo', 'Valeant Pharmaceuticals International', 'Otsuka Holidings', 'CSL', 'Baxalta', 'Shire', 'Sun Pharmaceutical Industries', 'Les Laboratories Servier Eisal', 'UCB', 'Abbott Laboratories', 'Fresenius', 'Grifols', 'Chugai Pharmaceutical', 'CJ (CheilJedang)', 'Mallinckrodt', 'Sumitomo Dainippon Pharma', 'Endo International', 'Menarini', 'Regeneron Pharmaceuticals', 'Alexion Pharmaceuticals', 'Aspen Pharmacare', 'Mitsubishi Tanabe Pharma', 'Nestle', 'Meda', 'Hospira']\n",
    "#for i in orgs:\n",
    "#    keywords(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook  :  ['facebook', 'users', 'social', 'user', 'com', 'zuckerberg', 'media', 'data', 'company', 'site', 'announced', 'people', 'privacy', 'mobile', 'friends', 'study', 'website', 'guardian', 'india', 'mark', 'network', 'networking', 'internet', 'ipo', 'like', 'time', 'video', 'wall', 'information', 'open', 'app', 'button', 'companies', 'using', 'google', 'use', 'used', 'year', 'online', 'photos', 'blog', 'bug', 'technology', 'age', 'allows', 'public', 'revenue', 'services', '000', 'active', 'content', 'myspace', 'techcrunch', 'articles', 'post', 'program', 'service', 'twitter', 'advertising', 'center', 'launched', 'political', 'profile', 'business', 'defunct', 'platform', 'policy', 'real', 'said', 'security', 'source', 'access', 'aol', 'feature', 'free', 'harvard', 'web', 'feed', 'help', 'number', 'php', 'reported', 'research', 'states', 'american', 'profiles', 'yahoo', 'according', 'corporation', 'high', 'live', 'microsoft', 'percent', 'posts', 'press', 'day', 'filed', 'following', 'headquarters', 'impact']\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import linalg,array,dot,mat,spatial\n",
    "from math import *\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sys\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "# please enter a word to check\n",
    "def keywords(centerWord):\n",
    "    url = \"http://en.wikipedia.org/wiki/\"+centerWord\n",
    "    req = requests.get(url)\n",
    "\n",
    "    statusCode = req.status_code\n",
    "    htmlText = req.text\n",
    "    \n",
    "    results = []\n",
    "    if statusCode == 200:\n",
    "        html = BeautifulSoup(req.text, \"lxml\")\n",
    "        res = html.find('div',id=\"bodyContent\")\n",
    "    else:\n",
    "        url = \"http://en.wikipedia.org/wiki/\"+centerWord+\"_(company)\"\n",
    "        req = requests.get(url)\n",
    "\n",
    "        statusCode = req.status_code\n",
    "        htmlText = req.text\n",
    "        \n",
    "    if statusCode == 200:\n",
    "        wikiText=res.getText()\n",
    "\n",
    "        stop_words = ['edit', '104m', '1837american', '1837companies', 'january', 'february', 'march', 'april', 'may',\n",
    "                      'june', 'july', 'august', 'september', 'october', 'november', 'december','original', \n",
    "                      'retrieved','archived','billion','million', 'new', 'news', 'pdf','world','based','www', \n",
    "                      'article','categories','les','la','pages','history','later','group','wellcome','list','united','york', 'times']+[str(num) for num in range(0,3018)]+['0'+str(x) for x in range(0, 10)]\n",
    "\n",
    "        stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)\n",
    "\n",
    "        tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df=0.001, stop_words=stop_words)\n",
    "\n",
    "        #oneset=(\" \".join(res))\n",
    "        #print(type(oneset))\n",
    "        tfidf_matrix = tf.fit_transform([wikiText.lower()[1000:]])\n",
    "\n",
    "        feature_names = tf.get_feature_names()\n",
    "\n",
    "        dense = tfidf_matrix.todense()\n",
    "        episode = dense[0].tolist()[0]\n",
    "        phrase_scores = [pair for pair in zip(range(0, len(episode)), episode) if pair[1] > 0]\n",
    "        sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "        dicto={}\n",
    "\n",
    "        sets=[]\n",
    "        for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:100]:\n",
    "            #print(\"'\"+str(phrase)+\"' = \"+str(score))\n",
    "            sets.append(str(phrase))\n",
    "\n",
    "        return sets\n",
    "    else:\n",
    "        return \"bad request\"\n",
    "\n",
    "# _(company)\n",
    "centerWord=\"facebook\"\n",
    "res=keywords(centerWord)\n",
    "print(centerWord,\" : \",res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook\n",
      "users\n",
      "social\n",
      "user\n",
      "com\n",
      "zuckerberg\n",
      "media\n",
      "data\n",
      "company\n",
      "site\n",
      "announced\n",
      "people\n",
      "privacy\n",
      "mobile\n",
      "friends\n",
      "study\n",
      "website\n",
      "guardian\n",
      "india\n",
      "mark\n",
      "network\n",
      "networking\n",
      "internet\n",
      "ipo\n",
      "like\n",
      "time\n",
      "video\n",
      "wall\n",
      "information\n",
      "open\n",
      "app\n",
      "button\n",
      "companies\n",
      "using\n",
      "google\n",
      "use\n",
      "used\n",
      "year\n",
      "online\n",
      "photos\n",
      "blog\n",
      "bug\n",
      "technology\n",
      "age\n",
      "allows\n",
      "public\n",
      "revenue\n",
      "services\n",
      "000\n",
      "active\n",
      "content\n",
      "myspace\n",
      "techcrunch\n",
      "articles\n",
      "post\n",
      "program\n",
      "service\n",
      "twitter\n",
      "advertising\n",
      "center\n",
      "launched\n",
      "political\n",
      "profile\n",
      "business\n",
      "defunct\n",
      "platform\n",
      "policy\n",
      "real\n",
      "said\n",
      "security\n",
      "source\n",
      "access\n",
      "aol\n",
      "feature\n",
      "free\n",
      "harvard\n",
      "web\n",
      "feed\n",
      "help\n",
      "number\n",
      "php\n",
      "reported\n",
      "research\n",
      "states\n",
      "american\n",
      "profiles\n",
      "yahoo\n",
      "according\n",
      "corporation\n",
      "high\n",
      "live\n",
      "microsoft\n",
      "percent\n",
      "posts\n",
      "press\n",
      "day\n",
      "filed\n",
      "following\n",
      "headquarters\n",
      "impact\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
